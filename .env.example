# Olumi Assistants Service - Environment Configuration
# Copy to .env and fill in actual values (never commit .env)

# Runtime
NODE_ENV=development
PORT=3101

# LLM Provider Configuration
# Options: "fixtures" (safe default, no API key needed), "anthropic", "openai"
LLM_PROVIDER=fixtures

# API Keys (required only if using real LLM providers)
# Leave blank when using LLM_PROVIDER=fixtures
ANTHROPIC_API_KEY=
OPENAI_API_KEY=

# Client Authentication
# Use ASSIST_API_KEYS (plural) for production with multiple clients (comma-separated)
# Use ASSIST_API_KEY (singular) for local dev with a single key
ASSIST_API_KEYS=
# ASSIST_API_KEY=

# Safety Limits
COST_MAX_USD=1.00
BODY_LIMIT_BYTES=1048576

# Timeouts & Retries
ASSISTANTS_TIMEOUT_MS=15000
ASSISTANTS_MAX_RETRIES=1
SSE_MAX_MS=120000

# CORS Configuration
# Comma-separated list of allowed origins, or "*" for local development only
# Production should use explicit origins (e.g., https://olumi.app,https://app.olumi.app)
ALLOWED_ORIGINS=*

# Rate Limiting
RATE_LIMIT_MAX=120
RATE_LIMIT_WINDOW_MS=60000

# Logging
LOG_LEVEL=info

PROMETHEUS_ENABLE=1
